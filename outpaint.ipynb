{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out Paint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D, AtrousConvolution2D\n",
    "from keras.layers import Activation, Dense, Input, Conv2DTranspose, Dense, Flatten\n",
    "from keras.layers import ReLU, Dropout, Concatenate, BatchNormalization, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "import IPython.display\n",
    "\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "\n",
    "from dataloader import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataloader\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (256, 256, 3)\n",
    "EPOCHS = 10000\n",
    "BATCH = 15\n",
    "\n",
    "# 25% i.e 64 width size will be mask from both side\n",
    "MASK_PERCENTAGE = .25\n",
    "\n",
    "\n",
    "CHECKPOINT = \"checkpoint/\"\n",
    "SAVED_IMAGES = \"saved_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "d_input_shape = (INPUT_SHAPE[0], int(INPUT_SHAPE[1] * (MASK_PERCENTAGE *2)), INPUT_SHAPE[2])\n",
    "d_dropout = 0.5\n",
    "DCRM_OPTIMIZER = Adam(0.0001, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_build_conv(layer_input, filter_size, kernel_size=4, strides=2, activation='leakyrelu', dropout_rate=d_dropout, norm=True):\n",
    "    c = Conv2D(filter_size, kernel_size=kernel_size, strides=strides, padding='same')(layer_input)\n",
    "    if activation == 'leakyrelu':\n",
    "        c = LeakyReLU(alpha=0.2)(c)\n",
    "    if dropout_rate:\n",
    "        c = Dropout(dropout_rate)(c)\n",
    "    if norm == 'inst':\n",
    "        c = InstanceNormalization()(c)\n",
    "    return c\n",
    "\n",
    "def build_discriminator():\n",
    "    d_input = Input(shape=d_input_shape)\n",
    "    d = d_build_conv(d_input, 64, 5,strides=2, norm=False)\n",
    "    for i in range(4):\n",
    "        filter_size = 128 * (2**i)\n",
    "        d = d_build_conv(d, 128, 5, strides=2)\n",
    "    flat = Flatten()(d)\n",
    "    fc1 = Dense(512, activation='relu')(flat)\n",
    "    d_output = Dense(1, activation='sigmoid')(fc1)\n",
    "    \n",
    "    return Model(d_input, d_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 64, 64)       4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 64, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 64, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 32, 128)       204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 16, 128)       409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 8, 128)        409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 8, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 8, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,537,153\n",
      "Trainable params: 3,537,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DCRM = build_discriminator()\n",
    "DCRM.summary()\n",
    "DCRM.compile(loss='mse', optimizer=DCRM_OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dropout = 0.5\n",
    "GEN_OPTIMIZER = Adam(0.001, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_build_conv(layer_input, filter_size, kernel_size=4, strides=2, activation='leakyrelu', dropout_rate=g_dropout, norm='inst', dilation=1):\n",
    "    c = AtrousConvolution2D(filter_size, kernel_size=kernel_size, strides=strides,atrous_rate=(dilation,dilation), padding='same')(layer_input)\n",
    "    if activation == 'leakyrelu':\n",
    "        c = ReLU()(c)\n",
    "    if dropout_rate:\n",
    "        c = Dropout(dropout_rate)(c)\n",
    "    if norm == 'inst':\n",
    "        c = InstanceNormalization()(c)\n",
    "    return c\n",
    "\n",
    "def g_build_deconv(layer_input, filter_size, kernel_size=3, strides=2, activation='relu', dropout=0):\n",
    "    d = Conv2DTranspose(filter_size, kernel_size=kernel_size, strides=strides, padding='same')(layer_input)\n",
    "    if activation == 'relu':\n",
    "        d = ReLU()(d)\n",
    "    return d\n",
    "\n",
    "def build_generator():\n",
    "    g_input = Input(shape=INPUT_SHAPE)\n",
    "    \n",
    "    g1 = g_build_conv(g_input, 128, 5, strides=1)\n",
    "    g2 = g_build_conv(g1, 256, 3, strides=2)\n",
    "    g3 = g_build_conv(g2, 512, 3, strides=1)\n",
    "    g4 = g_build_conv(g3, 512, 3, strides=1, dilation=2)\n",
    "    g5 = g_build_conv(g4, 512, 3, strides=1, dilation=4)\n",
    "    g6 = g_build_conv(g5, 512, 3, strides=1, dilation=8)\n",
    "    g7 = g_build_conv(g6, 512, 3, strides=1)\n",
    "    g8 = g_build_deconv(g7, 256, 4, strides=2)\n",
    "    g9 = g_build_conv(g8, 128, 3, strides=1)\n",
    "    \n",
    "    g_output = AtrousConvolution2D(3, kernel_size=3, strides=(1,2), activation='tanh',padding='same', atrous_rate=(1,1))(g9)\n",
    "    \n",
    "    return Model(g_input, g_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:301: UserWarning: The `AtrousConvolution2D` layer  has been deprecated. Use instead the `Conv2D` layer with the `dilation_rate` argument.\n",
      "  warnings.warn('The `AtrousConvolution2D` layer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 256, 256, 128)     9728      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 256, 256, 128)     2         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 128, 128, 256)     2         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 128, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 128, 128, 512)     2         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 128, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_4 (In (None, 128, 128, 512)     2         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 128, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_5 (In (None, 128, 128, 512)     2         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_6 (In (None, 128, 128, 512)     2         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 128, 128, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_7 (In (None, 128, 128, 512)     2         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 256, 256, 256)     2097408   \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 256, 256, 128)     295040    \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_8 (In (None, 256, 256, 128)     2         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 256, 128, 3)       3459      \n",
      "=================================================================\n",
      "Total params: 13,320,211\n",
      "Trainable params: 13,320,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generator Initialization\n",
    "GEN = build_generator()\n",
    "GEN.summary()\n",
    "GEN.compile(loss='mse', optimizer=GEN_OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = Input(shape=INPUT_SHAPE)\n",
    "DCRM.trainable = False\n",
    "GENERATED_IMAGE = GEN(IMAGE)\n",
    "CONF_GENERATED_IMAGE = DCRM(GENERATED_IMAGE)\n",
    "\n",
    "\n",
    "COMBINED = Model(IMAGE, [CONF_GENERATED_IMAGE, GENERATED_IMAGE])\n",
    "COMBINED.compile(loss=['mse', 'mse'], optimizer=GEN_OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking and De-Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_width(img):\n",
    "    image = img.copy()\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    new_width = int(width * MASK_PERCENTAGE)\n",
    "    mask = np.ones([height, new_width, 3])\n",
    "    missing_x = img[:, :new_width]\n",
    "    missing_y = img[:, width - new_width:]\n",
    "    missing_part = np.concatenate((missing_x, missing_y), axis=1)\n",
    "    image[:, :new_width] = mask\n",
    "    image[:, width - new_width:] = mask\n",
    "    return image, missing_part\n",
    "\n",
    "def get_masked_images(images):\n",
    "    mask_images = []\n",
    "    missing_images = []\n",
    "    for image in images:\n",
    "        mask_image, missing_image = mask_width(image)\n",
    "        mask_images.append(mask_image)\n",
    "        missing_images.append(missing_image)\n",
    "    return np.array(mask_images), np.array(missing_images)\n",
    "\n",
    "def get_demask_images(original_images, generated_images):\n",
    "    demask_images = []\n",
    "    for o_image, g_image in zip(original_images, generated_images):\n",
    "        width = g_image.shape[1] // 2\n",
    "        x_image = g_image[:, :width]\n",
    "        y_image = g_image[:, width:]\n",
    "        o_image[:, :width] = x_image\n",
    "        o_image[:, o_image.shape[1] - width:] = y_image\n",
    "        demask_images.append(o_image)\n",
    "    return np.asarray(demask_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "1. Save Model\n",
    "2. Load Model\n",
    "3. Save Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    global DCRM, GEN\n",
    "    models = [DCRM, GEN]\n",
    "    model_names = ['DCRM','GEN']\n",
    "\n",
    "    for model, model_name in zip(models, model_names):\n",
    "        model_path =  CHECKPOINT + \"%s.json\" % model_name\n",
    "        weights_path = CHECKPOINT + \"/%s.hdf5\" % model_name\n",
    "        options = {\"file_arch\": model_path, \n",
    "                    \"file_weight\": weights_path}\n",
    "        json_string = model.to_json()\n",
    "        open(options['file_arch'], 'w').write(json_string)\n",
    "        model.save_weights(options['file_weight'])\n",
    "    print(\"Saved Model\")\n",
    "    \n",
    "def load_model():\n",
    "    global DCRM, GEN\n",
    "    \n",
    "    # load DCRM Model\n",
    "    model_path = CHECKPOINT + \"%s.json\" % 'DCRM'\n",
    "    weight_path = CHECKPOINT + \"%s.hdf5\" % 'DCRM'\n",
    "    with open(model_path, 'r') as f:\n",
    "        DCRM = model_from_json(f.read())\n",
    "    DCRM.load_weights(weight_path)\n",
    "    DCRM.compile(loss='mse', optimizer=d_optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    #load GEN Model\n",
    "    model_path = CHECKPOINT + \"%s.json\" % 'GEN'\n",
    "    weight_path = CHECKPOINT + \"%s.hdf5\" % 'GEN'\n",
    "    with open(model_path, 'r') as f:\n",
    "         GEN = model_from_json(f.read())\n",
    "    GEN.load_weights(weight_path\n",
    "    \n",
    "    print(\"loaded model\")\n",
    "    \n",
    "    \n",
    "import cv2    \n",
    "def save_image(epoch, steps):\n",
    "    mask, original = data.get_data(1)\n",
    "    if mask is None:\n",
    "        mask, original = data.get_data(1)\n",
    "    \n",
    "    mask_image, missing_image = get_masked_images(original)\n",
    "    mask_image = mask_image / 127.5 - 1\n",
    "    missing_image = missing_image / 127.5 - 1\n",
    "    gen_missing = GEN.predict(mask_image)\n",
    "    demask_image = get_demask_images(mask_image, gen_missing)\n",
    "    \n",
    "    demask_image = (demask_image + 1) * 127.5\n",
    "    demask_image = demask_image.astype(np.uint8)\n",
    "    mask_image = (mask_image + 1) * 127.5\n",
    "    mask_image = mask_image.astype(np.uint8)\n",
    "    \n",
    "    file_name = str(epoch) + \"_\" + str(steps) + \".jpg\"\n",
    "    final_image = np.concatenate((original[0],mask_image[0], demask_image[0]), axis=1)\n",
    "    cv2.imwrite(os.path.join(SAVED_IMAGES, file_name), final_image)\n",
    "    \n",
    "    IPython.display.display(PIL.Image.fromarray(final_image))\n",
    "    print(\"image saved\")\n",
    "\n",
    "# save_image(1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(1, EPOCHS):\n",
    "        steps = 0\n",
    "        test = None\n",
    "        while True:\n",
    "            mask, original = data.get_data(BATCH)\n",
    "            if mask is None or original is None:\n",
    "                break\n",
    "            mask = mask / 127.5 - 1\n",
    "            batch_size = mask.shape[0]\n",
    "\n",
    "            mask_image, missing_image = mask_black(original)\n",
    "            mask_image = mask_image / 127.5 - 1\n",
    "            missing_image = missing_image / 127.5 - 1\n",
    "\n",
    "            # Discriminator\n",
    "            gen_missing = GEN.predict(mask_image)\n",
    "\n",
    "            real = np.ones([batch_size, 1])\n",
    "            fake = np.zeros([batch_size, 1])\n",
    "\n",
    "            d_loss_original = DCRM.train_on_batch(missing_image, real)\n",
    "            d_loss_mask = DCRM.train_on_batch(gen_missing, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_original, d_loss_mask)\n",
    "\n",
    "            # Generator\n",
    "            for i in range(2):\n",
    "                g_loss = COMBINED.train_on_batch(mask_image, [real, missing_image])\n",
    "            log = \"epoch: %d, steps: %d, DIS: %5f, GEN: %s\" %(epoch, steps, d_loss[0], str(g_loss))\n",
    "            print(log)\n",
    "            # Writing to log to 'log.txt'\n",
    "            with open('log.txt', 'a') as f:\n",
    "                f.write(\"%s\\n\"%log)\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "        if (epoch) % 10 == 0:\n",
    "            save_model()\n",
    "            save_image(epoch, steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
